{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align: left;\">\n",
    "      <h1>Lighthouse Labs</h1>\n",
    "      <h2>W4D4 - APIs and Other Data Types</h2>\n",
    "      <strong>Instructor:</strong> Socorro E. Dominguez-Vidana\n",
    "    </td>\n",
    "    <td style=\"text-align: right;\">\n",
    "      <img src=\"img/lhl.jpeg\" alt=\"LHL\" width=\"200\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sedv8808/LHL_Lectures/main?labpath=W4D4%2FW4D4_APIs_and_Other_Data_Types.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Overview:\n",
    "- [] Introduction to APIs\n",
    "    - [] Using APIs as a data professional\n",
    "    - [] Real-Life Examples\n",
    "    - [] HTTP Requests\n",
    "    - [] Sending requests from different environments\n",
    "    - [] Best practices for working with APIs\n",
    "- [] Other Data Types\n",
    "- [] Why is JSON so popular?\n",
    "- [] JSON vs XML?\n",
    "- [] Combining Python and Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Does Our Data Come From?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Everyday Data**: We interact with data constantly—whether we’re looking at our bank account, browsing social media, or searching for a restaurant to eat at.\n",
    "- **Sources of Data**: Data can come from many different places, and as a data scientist, understanding these sources is key to solving real-world problems.\n",
    "- **Why It Matters**: How we collect data influences what questions we can ask and what insights we can generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align: left;\">\n",
    "      <h1>Meet Jason</h1>\n",
    "      <strong>Name: </strong> Jason <br><br>\n",
    "      <strong>Hobby: </strong> Hiking, seismology, coding. <br><br>\n",
    "      <strong>Goal: </strong> Use data to predict earthquakes. <br><br>\n",
    "    </td>\n",
    "    <td style=\"text-align: right;\">\n",
    "      <img src=\"img/geologist.png\" alt=\"geologist\" width=\"75\"><br>\n",
    "      <a href=\"https://creazilla.com/media/clipart/1795355/safari-guide\" target=\"_blank\">Creazilla. (n.d.). Safari guide [Clip art]. Creazilla.</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How can Jason gather the data?\n",
    "\n",
    "- **Public Datasets**: Governments and research institutions often provide open data on seismic activity.\n",
    "- **Seismic Networks**: Organizations like the Global Seismographic Network (GSN) and local observatories gather seismic data from around the world.\n",
    "- **Historical Records**: Libraries, academic institutions, and online archives host datasets on past earthquakes.\n",
    "- **Crowdsourced Data**: Platforms like \"Did You Feel It?\" allow the public to report real-time observations of seismic activity.\n",
    "- **Private Companies**: Some tech and insurance companies also collect data for risk analysis and disaster response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Challenges:\n",
    "- **Data Fragmentation**: Data may have inconsistent formats and varying levels of detail.\n",
    "- **Manual Download**: Requires manual effort and is time-consuming.\n",
    "- If Jason wanted to mine data from the web (maybe private companies information):\n",
    "    - Almost all information is irrelevant\n",
    "    - Websites often require interaction (“Load More”, scrolling down)\n",
    "    - When websites update, the code will break\n",
    "    - Every website is different\n",
    "    - Companies actively try to stop data miners; data mining might be illegal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APIs in Data Science\n",
    "\n",
    "- **A**pplication **P**rogramming **I**nterfaces allow data scientists to **connect** with databases, **retrieve** data, and **automate** analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- APIs allow applications to communicate with each other serving as bridges between different data sources.\n",
    "- Many fields provide open data APIs for accessing information, including weather, finance, and geological data.\n",
    "- APIs simplify data collection without manually downloading files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why use APIs?\n",
    "\n",
    "- **Real-Time Data Access**: APIs like the **[USGS Earthquake API](https://earthquake.usgs.gov/fdsnws/event/1/)** provide up-to-the-minute seismic data, giving Jason instant access to recent earthquake activity.\n",
    "- **Consistency in Data Format**: APIs often return data in standardized formats (e.g., `JSON`, `CSV`, `XML`), making analysis much simpler.\n",
    "- **Data Customization**: APIs allow Jason to filter the data by criteria like *location*, *time range*, or *earthquake magnitude*, ensuring he gets only the data relevant to his analysis.\n",
    "- **Automation Capabilities**: Instead of manually checking data repositories, Jason can automate the process to continuously gather new data with scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representational State Transfer (REST)**\n",
    "\n",
    "- **Stateless**: Each API call is independent, with all necessary information included in the request.\n",
    "- **Resource-Based**: Interactions revolve around resources, identified by URIs.\n",
    "- **Use of HTTP (Hypertext Transfer Protocol) Methods**:\n",
    "    - **GET:** retrieve (the only one you will have access to right now.)\n",
    "    - **POST:** create\n",
    "    - **PUT:** update\n",
    "    - **DELETE:** remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing Seismic Data via the USGS Earthquake API\n",
    "\n",
    "Jason's new **BFF**: [Documentation](https://earthquake.usgs.gov/fdsnws/event/1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'format': 'geojson',\n",
    "    'starttime': '1023-01-01',\n",
    "    'endtime': '2024-10-02',\n",
    "    'latitude': 36.77,\n",
    "    'longitude': -119.41,\n",
    "    'maxradius': 50, \n",
    "    'minmagnitude': 5,\n",
    "    'limit': 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, params=params)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jason can extracts relevant data such as magnitude and location for analysis using other python libraries such as **matplotlib** and **pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['features']\n",
    "df = pd.json_normalize(features)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['magnitude'] = df['properties.mag']\n",
    "df['place'] = df['properties.place']\n",
    "df['time'] = pd.to_datetime(df['properties.time'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df['time'], df['magnitude'], alpha=0.5)\n",
    "plt.title('Magnitude of Earthquakes in California Over the Last 12 Years')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where is the USGS data really stored?\n",
    "\n",
    "- The USGS API provides access to a (possibly) *SQL* database of earthquake events collected and maintained by the USGS.\n",
    "- The data originates from various seismic networks and is updated in near real-time.\n",
    "- The database is not publicly accessible in the sense that you cannot download it and query it to your liking.\n",
    "- Each call that you do to the API possibly triggers a SQL function that yields the information back to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The API as a Server\n",
    "\n",
    "![api server](https://www.monosolutions.com/uploads/RY0RcBjd/pngbase6419c241d835623b8.png)\n",
    "[Monosolutions. (n.d.). Image of API server](https://www.monosolutions.com/uploads/RY0RcBjd/pngbase6419c241d835623b8.png)\n",
    "\n",
    "![api server](https://www.sqlshack.com/wp-content/uploads/2021/03/representational-state-transfer-diagram_gray-e1615546557211.png)\n",
    "[ SQL Shack. (2021). Representational state transfer diagram](https://www.sqlshack.com/wp-content/uploads/2021/03/representational-state-transfer-diagram_gray-e1615546557211.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disclaimer: Can Data Science Predict Earthquakes?\n",
    "\n",
    "- Short answer: Not yet. And **Domain Expertise** is crucial.\n",
    "- Earthquakes are caused by tectonic movements, but predicting the exact time and location remains a challenge.\n",
    "- Jason wants to use data science tools like machine learning to find patterns in seismic data.\n",
    "- Jason will need to **work closely** with geologists and seismologists to ensure his models are scientifically accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Terminal, a Browser, and Postman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!curl -G \"https://earthquake.usgs.gov/fdsnws/event/1/query\" \\\n",
    "--data-urlencode \"format=geojson\" \\\n",
    "--data-urlencode \"starttime=1924-10-01\" \\\n",
    "--data-urlencode \"endtime=2024-10-01\" \\\n",
    "--data-urlencode \"latitude=36.7783\" \\\n",
    "--data-urlencode \"longitude=-119.4179\" \\\n",
    "--data-urlencode \"maxradius=50\" \\\n",
    "--data-urlencode \"minmagnitude=0.0\" \\\n",
    "--data-urlencode \"limit=1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=1924-10-01&endtime=2024-10-01&latitude=36.7783&longitude=-119.4179&maxradius=50&minmagnitude=0.0&limit=1](https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=1924-10-01&endtime=2024-10-01&latitude=36.7783&longitude=-119.4179&maxradius=50&minmagnitude=0.0&limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Paid APIs and Authentication Keys\n",
    "\n",
    "- The API will requires an Authentication Key\n",
    "- Register on the API provider’s website to obtain access.\n",
    "- After account creation, navigate to the API settings or dashboard.\n",
    "- Locate the section for generating API keys or tokens.\n",
    "- Follow the instructions to create a new key.\n",
    "- **Read the API Documentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import requests\n",
    "\n",
    "url = \"https://api.fakeusgs.com/v1/seismic\"\n",
    "\n",
    "# Keep your API secure using environment variables\n",
    "api_key = os.getenv(\"WEATHER_API_KEY\")\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    \"latitude\": 10,\n",
    "    \"longitude\": 80,\n",
    "    \"limit\": 100}\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Accept\": \"application/json\" }\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix I: Common HTTP Status Codes\n",
    "\n",
    "- **200 OK**: Success.\n",
    "- **204 No Content**: No content.\n",
    "- **400 Bad Request**: Invalid syntax.\n",
    "- **401 Unauthorized**: Authentication is required and has failed/not been provided.\n",
    "- **403 Forbidden**: The server cannot authorize it.\n",
    "- **404 Not Found**: The resource was not found on the server.\n",
    "- **500 Internal Server Error**: The server could not fulfil the request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other Data Formats\n",
    "\n",
    "| Data Format | Example | What are we trying to use it for? |\n",
    "|:-|:---------------------|:--------------------------------------------|\n",
    "| Text         | Tweets, scripts, books | Sentiment analysis, other NLP |\n",
    "| JSON or XML  | Parsing APIs | Gather data, data ingestion process, trend analysis, forecasting |\n",
    "| HTML         |Web scraping| Get information where APIs are not available.|\n",
    "| Images       |Computer vision|Self-driving cars, building custom shoes, X-rays - diagnostics|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Different data, different tools\n",
    "\n",
    "* Tabular data: `pandas`, `SQL`\n",
    "* XML: `xml`\n",
    "* JSON: `json`\n",
    "* HTML: `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON vs XML\n",
    "\n",
    "| Feature        | JSON      | XML           |\n",
    "|-----------------------|---------------------------------------|----------------------------------------|\n",
    "| **Syntax**            | Uses braces `{}` and brackets `[]`           | Nested tags  `<>`                          |\n",
    "| **Verbosity**         | Less verbose                          | Complex |\n",
    "| **Data Types**        | Supports arrays and objects natively  | Requires additional attributes for lists|\n",
    "| **Parsing**           | Easier to parse with built-in functions| Requires a parser for XML structure   |\n",
    "| **Human Readability** | Easier for humans to read and write  | More complex structure can be harder to read |\n",
    "| **Use Cases**         | APIs and configuration | Document storage and data interchange |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "  <tr>\n",
    "    <th>XML</th>\n",
    "    <th>JSON</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <pre>\n",
    "&lt;earthquakes&gt;\n",
    "  &lt;earthquake&gt;\n",
    "    &lt;magnitude&gt;4.5&lt;/magnitude&gt;\n",
    "    &lt;location&gt;10 km N of Turlock, CA &lt;/location&gt;\n",
    "    &lt;date&gt;2021-09-01&lt;/date&gt;\n",
    "  &lt;/earthquake&gt;\n",
    "&lt;/earthquakes&gt;\n",
    "      </pre>\n",
    "    </td>\n",
    "    <td>\n",
    "      <pre>\n",
    "{\n",
    "  \"earthquakes\": {\n",
    "    \"earthquake\": {\n",
    "      \"magnitude\": 4.5,\n",
    "      \"location\": \"10 km N of Turlock, CA\",\n",
    "      \"date\": \"2021-09-01\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "      </pre>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th colspan=\"2\">Tabular</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\">\n",
    "      <table border=\"1\">\n",
    "        <tr>\n",
    "          <th>Magnitude</th>\n",
    "          <th>Location</th>\n",
    "          <th>Date</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>4.5</td>\n",
    "          <td>10 km N of Turlock, CA</td>\n",
    "          <td>2021-09-01</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why Save Data After Downloading from an API\n",
    "\n",
    "- **Data Integrity**: Preserve a stable copy in case of API changes or outages.\n",
    "- **Performance**: Faster local access improves application efficiency.\n",
    "- **Flexibility**: Enables easier manipulation and analysis without API constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### XML and BeautifulSoup\n",
    "- Explore XML files with the `xml` or `BeautifulSoup` package.\n",
    "- Data file provided: `toy_data.xml` and `usgs_data.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tree = et.parse('data/toy_data.xml')\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Gets the tree root tag\n",
    "root = tree.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From the root, we can begin to navigate the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# get root tag\n",
    "print(\"What is the root tag:\", root.tag)\n",
    "\n",
    "# get root attributes\n",
    "print(\"Attributes of the root tag:\", root.attrib)\n",
    "\n",
    "# get number of \"children\"\n",
    "print(\"Number of children:\", len(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for idx in range(len(root)):\n",
    "    print(\"tag:\", root[idx].tag, \"| attribute:\", root[idx].attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = root[0].attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/toy_data.xml', 'r') as file:\n",
    "    xml_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = xmltodict.parse(xml_data)\n",
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(xml_data, 'lxml-xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('earthquake')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON\n",
    "\n",
    "- Explore JSON files with the `json` and `pandas`.\n",
    "- Data file provided: `toy_data.json` and `usgs_data.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = 'data/toy_data.json'\n",
    "json_data = pd.read_json(file)\n",
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `pd.read_json` doesn't always work with nested **JSON** files...\n",
    "- You may encounter `ValueErrors` as it tries to create a `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/toy_data.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Just Jupyter Lab\n",
    "JSON(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.json_normalize(data['seismic_data'], \n",
    "                       record_path=['earthquake_data', 'earthquakes'], \n",
    "                       meta=['region'],  # Meta data at the higher level\n",
    "                       meta_prefix='_',  # Prefix for clarity\n",
    "                       errors='ignore') # Explore ignore/raise\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = []\n",
    "\n",
    "for region_info in data['seismic_data']:\n",
    "    region = region_info.get('region', 'Unknown')\n",
    "    for earthquake_data in region_info.get('earthquake_data', []):\n",
    "        for earthquake in earthquake_data.get('earthquakes', []):\n",
    "            flattened_entry = {\n",
    "                'magnitude': earthquake['magnitude'],\n",
    "                'location': earthquake['location'],\n",
    "                'date': earthquake['date'],\n",
    "                'region': region\n",
    "            }\n",
    "            flattened_data.append(flattened_entry)\n",
    "pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Other forms of tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_xlsx = pd.read_excel('data/toy_tabular.xlsx')\n",
    "data_xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Excel Files\n",
    "- As a Data Analyst and Scientist, you need to know both.\n",
    "- It is not a competition.\n",
    "- Excel files can be very practical and widely understood/used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Tab2.png\" alt=\"Tabular Image\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/Tab1.png\" alt=\"Tabular Image\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- After exploring the file, we know that the data is on `Tab 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xlsx = pd.read_excel('data/toy_tabular.xlsx', \n",
    "                          sheet_name='Data', \n",
    "                          header=1, \n",
    "                          usecols='B:E',\n",
    "                          engine = 'openpyxl')\n",
    "data_xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful Links\n",
    "\n",
    "[JSON Plug-in](https://chrome.google.com/webstore/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa?hl=en)\n",
    "\n",
    "Gulati, A. (2021, April 20). All Pandas json_normalize you should know for flattening JSON. Towards Data Science. [https://towardsdatascience.com/all-pandas-json-normalize-you-should-know-for-flattening-json-13eae1dfb7dd](https://towardsdatascience.com/all-pandas-json-normalize-you-should-know-for-flattening-json-13eae1dfb7dd)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
