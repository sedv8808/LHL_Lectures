{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align: left;\">\n",
    "      <h1>Lighthouse Labs</h1>\n",
    "      <h2>W4D5 - Introduction to Exploratory Data Analysis (EDA)</h2>\n",
    "      <strong>Instructor:</strong> Socorro E. Dominguez-Vidana\n",
    "    </td>\n",
    "    <td style=\"text-align: right;\">\n",
    "      <img src=\"img/lhl.jpeg\" alt=\"LHL\" width=\"200\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sedv8808/LHL_Lectures/main?labpath=W4D5%2FW4D5_Intro_to_EDA.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Overview:\n",
    "- [] Introduction to EDA\n",
    "- [] Statistics for EDA\n",
    "- [] Data visualization for EDA\n",
    "    - [] Matplotlib\n",
    "    - [] Seaborn\n",
    "    - [] Plotly\n",
    "- [] Outlier Detection\n",
    "- [] Handling Missing Values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "- EDA involves exploration and preliminary analysis of a dataset.\n",
    "- Involves examining summary statistics and exploring visualizations of the data. \n",
    "- Can uncover anomalies, patterns, and relationships between variables.\n",
    "- EDA usually goes hand-in hand with data cleaning.\n",
    "- Further examination can be done by using hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align: left;\">\n",
    "      <h1>Meet Aisha</h1>\n",
    "      <p>  Aisha is an urban planner tasked with designing new urban spaces in a major European city, where rapid urbanization has caused several issues, including the formation of <strong>U</strong>rban <strong>H</strong>eat <strong>I</strong>slands. <strong>UHI</strong>s result in elevated temperatures in certain areas of the city, which negatively affect public health and increase energy consumption. </p><p>\n",
    "\n",
    "Aisha found [Open AQ](https://openaq.org/), an API that contains pollution data. She also found Weather Data for her city using the [Meteostat](https://dev.meteostat.net/python/#installation) Python library. Once the data has been downloaded, Aisha will do **E**xploratory **D**ata **A**nalysis (**EDA**) to identify *pollution* and *temperature* patterns that contribute to these heat islands and find ways to mitigate them through smarter urban planning.\n",
    "</p>\n",
    "    </td>\n",
    "    <td style=\"text-align: right;\">\n",
    "      <img src=\"https://png.pngtree.com/png-vector/20221205/ourmid/pngtree-muslim-woman-using-laptop-png-image_6511735.png\" alt=\"geologist\" width=\"500\"><br>\n",
    "      <a href=\"https://png.pngtree.com/png-vector/20221205/ourmid/pngtree-muslim-woman-using-laptop-png-image_6511735.png\" target=\"_blank\">Muslim Girl Using Laptop</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/amsterdam_AQ.csv', parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the raw data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the data dictionary **Aisha** wrote, just in case, in the future she forgets what the data means:\n",
    "\n",
    "| **Field Name**        | **Description**                                               | **Data Type**        | **Example Value**        |\n",
    "|-----------------------|---------------------------------------------------------------|----------------------|---------------------------|\n",
    "| `sensor_id`           | Unique identifier for the air quality sensor                 | String or Integer    | `12345`                   |\n",
    "| `parameter`           | Air quality parameter being measured (e.g., pollutants)      | String               | `PM2.5`                   |\n",
    "| `parameter_units`     | Units of measurement for the parameter                        | String               | `µg/m³`                   |\n",
    "| `value`               | Measured value of the parameter                               | Float or Integer     | `15.2`                    |\n",
    "| `date`                | Date of the measurement                              | Datetime             | `2022-09-01`   |\n",
    "| `latitude`            | Latitude of the sensor's location                             | Float                | `52.3676`                 |\n",
    "| `longitude`           | Longitude of the sensor's location                            | Float                | `4.9041`                  |\n",
    "| `tavg`                | Average temperature at the time of measurement               | Float                | `18.5`                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aisha's Goal:**  explore how pollution and temperature interact and where heat patterns occur.\n",
    "\n",
    "**What does she need?** Measurements of pollutants like **CO**, **NO2**, and temperature variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Data Exploration\n",
    "\n",
    "- Generates summary statistics\n",
    "- Visualize the distribution of temperature and pollutants to identify any initial trends or potential issues like missing data or errors in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we can see that there are some statistics, the `parameter` column does not seem very useful as it is.\n",
    "\n",
    "For our analysis, we really do not need the `sensor_id` data, as each sensor only captures one pollutant. Let's remove the `sensor_id` and pivot the table so that we actually see the important parameters.\n",
    "\n",
    "Let's display a few rows of the `DataFrame` to have an idea if this is what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns = 'sensor_id').pivot_table(index=['date', 'latitude',\n",
    "       'longitude', 'tavg'], columns='parameter', values='value').reset_index()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe a specific date.\n",
    "df2[df2['date'] == '2022-08-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize summary of statistics\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations we can make:\n",
    "- **Date**: The data only compresses one year.\n",
    "- **Carbon Monoxide (CO)**: The negative minimum may indicate data issues or errors in measurement or reporting.\n",
    "- **Nitric Oxide (NO)**: It seems to have a high standard deviation...\n",
    "- **Nitrogen Dioxide (NO2)**: Some days, there seems to be a moderate level of air pollution.\n",
    "- **Ozone (O3)**: Some days, there is a high ozone concentration (maximum of 110).\n",
    "- **Particulate Matter**: Some days it seems high.\n",
    "- **Sulfur Dioxide (SO2)** Average of 0.69, some days, it goes really high with 3.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In `pd.describe()` **NaN**s are not used in statistical calculations (e.g., average, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df2.isnull().sum()\n",
    "missing_percentage = (missing_values / df2.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "missing_data[missing_data['Missing Values'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Why do **Missing Values** happen?\n",
    "- The sensor might have not worked that day.\n",
    "- If it is a survey, people may choose to not answer.\n",
    "- Value that is inconsistently recorded.\n",
    "\n",
    "Based on the missing values, we need to decide how to handle them. \n",
    "Some possible options are:\n",
    "\n",
    "- Dropping rows with missing values\n",
    "- Imputing missing values with the `mean`, `median`, or `mode` \n",
    "- Use regression or another ML method.\n",
    "\n",
    "**Discussion:** Why do we have so many \"missing values\" in this particular data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill all missing values with the mean of the column by simply doing:\n",
    "\n",
    "```python\n",
    "df_filled = df2.fillna(df2.mean())\n",
    "```\n",
    "\n",
    "But think if that would be enough and document your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it feasible to drop rows with `NaN`s for us today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling missing values with the mean after grouping by date.\n",
    "df_filled = df2.groupby(['date']).transform(lambda x: x.fillna(x.mean()))\n",
    "df_filled['date'] = df2['date']\n",
    "\n",
    "# Filling missing values by location afterwards\n",
    "df_filled = df_filled.groupby(['latitude', 'longitude']\n",
    "                             ).transform(lambda x: x.fillna(x.mean()))\n",
    "df_filled['latitude'] = df2['latitude']\n",
    "df_filled['longitude'] = df2['longitude']\n",
    "df_filled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df_filled.isnull().sum()\n",
    "missing_percentage = (missing_values / df_filled.shape[0]) * 100\n",
    "missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "missing_data[missing_data['Missing Values'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You an also remove when there are too many nulls just in the row and if this is possible.\n",
    "\n",
    "For that:\n",
    "```python\n",
    "df_filled = df_filled.dropna(thresh=len(df_filled.columns) - 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Data Distribution\n",
    "\n",
    "Understanding the distribution of air quality data is crucial for Aisha. It informs her about the typical levels of pollutants and helps identify potential health risks for residents. For instance, high levels of **PM2.5** can lead to respiratory issues, making it essential to monitor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **box-plot** is also often used to examine distributions. Here you can visualize the `min`, `max`, each of the `quartiles`, the `IQR`, and any **\"outliers\"**. \n",
    "\n",
    "In the default box-plot settings, outliers are determined to be those which are larger than $Q_3 + 1.5 \\times IQR$ or smaller than $Q_1 - 1.5 \\times IQR$. This value of 1.5 can be changed by specifying the `whis` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1** and **Example 2** in [W4D5_Examples.ipynb](W4D5_Examples.ipynb)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sedv8808/LHL_Lectures/main?labpath=W4D5%2FW4D5_Examples.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df_filled.melt(value_vars=['co', 'no', 'no2', 'o3', 'pm10', 'pm25', 'so2'],\n",
    "                            var_name='parameter', \n",
    "                            value_name='value')\n",
    "df_melted.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='parameter', y='value', data=df_melted)\n",
    "plt.title('Box Plot of Pollutants')\n",
    "plt.xlabel('Pollutants')\n",
    "plt.ylabel('Concentration (µg/m³)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More null values\n",
    "- Sometimes `null` values aren't exactly `NaN`s\n",
    "- They are encoded as `-1`, `0`, or `9999` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aisha examines the box plots and detects what she had seen from the summary of statistics before. She has `negative` values. She researches and finds out that those are possibly errors from the sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pollutant in df_melted['parameter'].unique():\n",
    "    print(f\"Negative values for {pollutant}: {(df_filled[pollutant] < 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "She decides to remove rows with negative values as they make no sense and she cannot find a person who can explain those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter numeric columns\n",
    "numeric_cols = df_filled.select_dtypes(include='number')\n",
    "\n",
    "# Remove rows where there is a negative value\n",
    "df_filled = df_filled[(numeric_cols >= 0).all(axis=1)]\n",
    "df_filled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it was just `0` and you preferred replacing them:\n",
    "```python\n",
    "# cols with inappropriate 0s\n",
    "cols_missing_vals = ['pm25', 'o3']\n",
    "\n",
    "# replace 0's with NaNs\n",
    "df_filled[cols_missing_vals] = df_filled[cols_missing_vals].replace(0, np.NaN)\n",
    "df_filled.isnull().sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing a Single Variable at a Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful visualization for EDA is a **histogram**. A histogram gives us an idea of the **distribution** of a set of numbers. \n",
    "\n",
    "**Example 3** and **Example 4** in [W4D5_Examples.ipynb](W4D5_Examples.ipynb) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sedv8808/LHL_Lectures/main?labpath=W4D5%2FW4D5_Examples.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "\n",
    "sns.histplot(df_filled['o3'], bins=30, ax=axes[0])\n",
    "axes[0].set_title('Distribution of O3 Levels')\n",
    "axes[0].set_xlabel('O3 (µg/m³)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(df_filled['o3'], bins=30, color='green', ax=axes[1])\n",
    "axes[1].set_title('Distribution of O3 Levels')\n",
    "axes[1].set_xlabel('O3 (µg/m³)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_xlim(left=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, \n",
    "                         ncols=2, \n",
    "                         figsize=(14, 10))\n",
    "\n",
    "sns.histplot(df_filled['o3'], bins=30, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Distribution of O3 Levels')\n",
    "axes[0, 0].set_xlabel('O3 (µg/m³)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(df_filled['no'], bins=30, color='green', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Distribution of NO Levels')\n",
    "axes[0, 1].set_xlabel('NO (µg/m³)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(df_filled['so2'], bins=30, color='grey', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Distribution of SO2 Levels')\n",
    "axes[1, 0].set_xlabel('SO2 (µg/m³)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(df_filled['tavg'], bins=30, color='orange', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Distribution of Temperature')\n",
    "axes[1, 1].set_xlabel('Temperature')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_xlim(left=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df_filled, x='pm25', fill=True, label='PM25')\n",
    "plt.title('Distribution of PM25 Levels')\n",
    "plt.xlabel('PM25 (µg/m³)')\n",
    "plt.ylabel('Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 5** in  [W4D5_Examples.ipynb](W4D5_Examples.ipynb) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sedv8808/LHL_Lectures/main?labpath=W4D5%2FW4D5_Examples.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness\n",
    "\n",
    "From the two plots above, Alisha notices that the distribution of \"PM25\" is leaning more towards the left, it is left-skewed. \n",
    "\n",
    "Some ML models assume naively that the data is:\n",
    "- symmetrical or \"**normally distributed**\"\n",
    "\n",
    "In future lectures pay attention to:\n",
    "- Hypothesis testing (Is the data normally distributed?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Outlier Detection\n",
    "\n",
    "- **Outliers** are observations that seem distant from other data points and may indicate something happened in the data.\n",
    "- As **valid** data points:\n",
    "    - During a local fire, a very high air pollution reading.\n",
    "    - Weather conditions such as temperature or wind speed can significantly influence pollution levels.\n",
    "- As **errors**:\n",
    "    - Measurements issues (malfunction of the sensor).\n",
    "    - Data entry issue (typing a wrong number).\n",
    "\n",
    "- To deal with errors, often **domain-specific knowledge** is required to determine the proper course of action.\n",
    "\n",
    "> Note: Before simply deleting outliers, determine if this is needed. It depends on your use case and if the outliers are important (e.g., fraud detection).\n",
    "\n",
    "For now:\n",
    "\n",
    "- Drop the observation (if appropriate)\n",
    "- Consider fixing the observation (e.g., obvious typo, missing value)\n",
    "- Explore what caused the outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-scores\n",
    "\n",
    "Another way to detect outliers is by identifying observations with a **z-score** greater than 3. A **z-score** indicates how many standard deviations an observation is from the mean, so values with **z-scores** above 3 are considered significantly different from the average and could be potential outliers.\n",
    "\n",
    "$$\n",
    "Z = \\dfrac{x-\\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "**Rule of thumb**\n",
    "- **label values with a z-score above 3 as outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filled['pm25'][np.abs((df_filled['pm25'] - df_filled['pm25'].mean()) / df_filled['pm25'].std())>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "stats.zscore(df_filled['pm25'])\n",
    "np.abs(stats.zscore(df_filled['pm25']))\n",
    "df_filled['pm25'][(np.abs(stats.zscore(df_filled['pm25'])) > 3)].head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data visualization for EDA on multiple variables\n",
    "\n",
    "Up until now, we have only been exploring a single variable at a time. (\"*Single Variant Analysis*\")\n",
    "\n",
    "Another part of EDA is examining multiple variables at the same time to look for trends, patterns, or relationships between variables. (\"*Multi Variant Analysis*\")\n",
    "\n",
    "We can create a histogram-equivalent on two variables by having each variable on the `x` and `y` axes, and have the counts be represented by color density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "sns.histplot(data=df_filled, x='o3', y='pm25', ax=ax[0])\n",
    "ax[0].set_title('Density Plot', fontsize=16)\n",
    "\n",
    "sns.kdeplot(data=df_filled, x='o3', y='pm25', fill=True, ax=ax[1])\n",
    "ax[1].set_title('Kernal Density Plot', fontsize=16)\n",
    "\n",
    "sns.scatterplot(data=df_filled, x='o3', y='pm25',alpha=0.7, ax=ax[2])\n",
    "ax[2].set_title('Scatter Plot', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(\n",
    "    data=df_filled, \n",
    "    x='pm25', \n",
    "    y='o3',\n",
    "    height=5\n",
    ")\n",
    "plt.suptitle('Joint Plot Comparing PM25 to O3', y=1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- There seems to be no clear linear relationship between `PM2.5` and `O3`.\n",
    "- The lack of a clear trend between `PM2.5` and `O3` could indicate that these two pollutants are not directly correlated in this dataset. External factors such as weather conditions, geographic location, and time of year could play a role in the observed concentrations.\n",
    "- A cluster of points is visible at lower `PM2.5` values (less than 15), with `O3` levels varying widely from near 0 to over 80.\n",
    "- The marginal histograms give insight into the overall distribution of both pollutants, showing that `PM2.5` levels tend to be lower overall, while `O3` levels are more widely distributed.\n",
    "\n",
    "- Linear relationships between two variables can be identified by examining the **correlation** between the two variables. Pandas has a convenient `.corr()` method to view the correlations between all variables at once via its **correlation matrix**.\n",
    "\n",
    "> Correlation is a number between -1 and 1. Correlation is positive when the variables increase together, and\n",
    "Correlation is negative when one variable decreases as the other increases. A correlation near zero indicates the variables are not linearly related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas method\n",
    "df_filled.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view this correlation matrix in a visually pleasing way by using a seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(df_filled.corr(), cmap='Blues', annot=True, annot_kws={'fontsize': 8})\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mask = np.triu(np.ones_like(df_filled.corr(), dtype=bool), k=1)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    df_filled.corr(),\n",
    "    mask=mask,\n",
    "    cmap='Blues',\n",
    "    annot=True,\n",
    "    cbar=False,\n",
    "    annot_kws={'fontsize': 8})\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aisha can view different graphs that perform pairwise comparisons all at once beyond just looking at the correlation. \n",
    "\n",
    "To view and compare many distributions at the same time, use `pairplot()` or `pairgrid()` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_filled[['co', 'no', 'no2', 'o3', 'pm10', 'pm25', 'so2', 'tavg']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.PairGrid(df_filled[['co', 'no', 'no2', 'o3', 'pm10', 'pm25', 'so2', 'tavg']])\n",
    "\n",
    "ax.map_upper(sns.scatterplot)\n",
    "ax.map_lower(sns.kdeplot, fill=True)\n",
    "ax.map_diag(sns.histplot, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying info of more than two variables\n",
    "Most of the time in seaborn, plotting functions take in an optional `hue` parameter which corresponds to a **categorical** variable that will be used to group the data using different colors. The colours and legend will be created automatically, but can be customized using parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a 3rd variable\n",
    "```python\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=df_filled, x='pm25', y='o3', hue='pollution_level', s=75)\n",
    "plt.legend(loc='upper left', fontsize='x-large')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a 4th variable\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=df_filled, x='pm25', y='o3', hue='pollution_level', size='month')\n",
    "plt.show()\n",
    "```\n",
    "**Note:** More dimensions = more difficult to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Trends Over Time\n",
    "\n",
    "Aisha would also like to see the trends in air quality over time to identify patterns, such as seasonal variations in pollution levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting trends for PM2.5\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(data=df_filled, x='date', y=df_filled['pm25'], errorbar=None)\n",
    "plt.title('PM2.5 Levels Over Time in Amsterdam')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5 (µg/m³)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why 3 different visualizing libraries?\n",
    "\n",
    "#### Visualizing Pollution Distribution with a Heatmap\n",
    "\n",
    "To gain deeper insights into air quality across different locations in Amsterdam, Aisha decides to create a heatmap. This visualization will help her understand which areas are most affected by pollution, allowing her to focus her urban planning efforts effectively.\n",
    "\n",
    "Using `latitude` and `longitude` lets create a heatmap of `PM2.5` concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# Set the renderer to use in Jupyter Notebook\n",
    "pio.renderers.default = 'iframe'  # or 'notebook_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_min = df_filled['pm25'].min()\n",
    "global_max = df_filled['pm25'].max()\n",
    "\n",
    "fig = px.density_mapbox(\n",
    "    df_filled,\n",
    "    lat='latitude',\n",
    "    lon='longitude',\n",
    "    z='pm25',\n",
    "    radius=10,\n",
    "    center=dict(lat=52.3676, lon=4.9041),\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    zoom=10,\n",
    "    animation_frame='date',\n",
    "    title='PM2.5 Concentrations in Amsterdam Over Time',\n",
    "    range_color=[global_min, global_max],   # Set fixed maximum for color scale\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "- Visualizing data is a key part of the **EDA** process.\n",
    "- Tools that we used:\n",
    "    - **Matplotlib**: usually used when you want to quickly make a simple plot, or when you want very fine-grained control over every aspect of the plot.\n",
    "    - **Seaborn**: usually used when presenting visualizations at a more professional level or when attempting to visualize more complex relationships easily. It is built on top of matplotlib, so you can use matplotlib to fine-tune your seaborn plots.\n",
    "    - **Plotly**: usually used when you would like interactivity. Steeper learning curve and uses its own syntax.\n",
    "\n",
    "\n",
    "- Visualization allows us to **interpret** and **summarize** large amounts of data in an efficient manner rather than just looking at the raw data or summary statistics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly Favs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_cols =['tavg', 'o3', 'so2']\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_filled,\n",
    "    x='pm25',\n",
    "    y='pm10',\n",
    "    marginal_x='histogram',\n",
    "    marginal_y='histogram',\n",
    "    hover_data=hover_cols,\n",
    "    title='PM25 vs. PM10'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.abs(df_filled.corr())\n",
    "\n",
    "fig = px.imshow(corr_matrix, color_continuous_scale='RdBu_r')\n",
    "\n",
    "fig.update_layout(\n",
    "    title = 'Correlation Heatmat',\n",
    "    xaxis = dict(title='Features'),\n",
    "    yaxis = dict(title='Features')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
