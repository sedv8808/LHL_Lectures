{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2efa0b-15bd-4f08-8c14-b648b664343a",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align: left;\">\n",
    "      <h1>Lighthouse Labs</h1>\n",
    "      <h2>W10D5 - LLM Deployment & LLM Ethics</h2>\n",
    "      <strong>Instructor:</strong> Socorro E. Dominguez-Vidana\n",
    "    </td>\n",
    "    <td style=\"text-align: right;\">\n",
    "      <img src=\"img/lhl.jpeg\" alt=\"LHL\" width=\"200\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc94b5-844e-4037-8736-e8f8b053e718",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sedv8808/LHL_Lectures/main?labpath=W10D5%2FW10D5_LLM_Deployment_and_LLM_Ethics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa63fd-609e-4e9a-9c6d-f78a4075589d",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- [] Whose Role is it?\n",
    "- [] LLM Deployment\n",
    "- [] Deployment Patterns\n",
    "- [] Demo\n",
    "- [] LLM Ethics\n",
    "- [] Ethical Considerations\n",
    "- [] Potential Unethical Use Cases\n",
    "- [] Model Cards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2dcd92-8cb5-40dd-adbd-de497ee83f7a",
   "metadata": {},
   "source": [
    "## (LLM) Deployment\n",
    "\n",
    "![](https://arize.com/wp-content/uploads/2023/06/deploy-large-language-model-lifecycle.png)\n",
    "\n",
    "[Arize AI. (n.d.). Large Language Model (LLM) deployment. Arize AI. Retrieved June 17, 2024](https://arize.com/blog-course/large-language-model-llm-deployment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d184a2c-2165-45b0-b994-dd852fdb4912",
   "metadata": {},
   "source": [
    "### Whose Role is it?\n",
    "\n",
    "![](https://www.hibernian-recruitment.com/wp-content/uploads/2023/05/data-captains-radar-chart.jpg)\n",
    "\n",
    "[Hibernian Recruitment. (n.d.). What’s a data scientist? Explaining roles in big data. Hibernian Recruitment. Retrieved June 17, 2024](https://www.hibernian-recruitment.com/en/whats-a-data-scientist-explaining-roles-in-big-data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ca6b6-8279-41c9-93b3-3862a97b7aad",
   "metadata": {},
   "source": [
    "##### Deployment is a TEAM effort\n",
    "- Besides technical roles, you also need:\n",
    "    - Ethics / Compliance Officers\n",
    "    - Legal departments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ce10d-7531-4d7f-8e1d-8dd5590fcddd",
   "metadata": {},
   "source": [
    "### Deployment Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce07fa-c380-4d28-991c-9c3d177b018e",
   "metadata": {},
   "source": [
    "![](https://www.genesesolution.com/wp-content/uploads/2022/08/On-premises-vs-Cloud-base-bnr-980x551.png)\n",
    "\n",
    "[Genese Solution. (n.d.). On-premises vs cloud. Genese Solution. Retrieved June 17, 2024](https://www.genesesolution.com/blog/on-premises-vs-cloud/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37290ffc-55b3-4c0b-9521-ae49dd115f96",
   "metadata": {},
   "source": [
    "##### Cloud \n",
    "- Flexible and easy to scale.\n",
    "\n",
    "##### On-prem\n",
    "- Considered for data security."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e20d3e-038e-4704-9a92-419cbf82398f",
   "metadata": {},
   "source": [
    "### Deployment Options\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*86ytqzOii135BOfAv3HYZA.png)\n",
    "\n",
    "[InAccel. (2020, August 19). CPU, GPU, FPGA, or TPU: Which one to choose for my machine learning training? Medium. Retrieved June 17, 2024](https://inaccel.medium.com/cpu-gpu-fpga-or-tpu-which-one-to-choose-for-my-machine-learning-training-948902f058e0)\n",
    "\n",
    "This will depend on the usecase:\n",
    "- Real time\n",
    "- Serverless\n",
    "- Batch transfroms\n",
    "- Asynchronous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4ca41-46f6-4e3c-a306-5a2376593cae",
   "metadata": {},
   "source": [
    "#### Managing Resources\n",
    "\n",
    "##### Resource Optimization\n",
    "- Model compression/Quantization/Prunning help:\n",
    "    - Reduce memory requirements\n",
    "    - Enhance computational efficiency\n",
    "    - Reduce latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61817b1e-ad65-4b88-b0c0-c52b7aa00a98",
   "metadata": {},
   "source": [
    "## Demo - Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4b86b-9944-46a6-b08a-43a5b0cc604a",
   "metadata": {},
   "source": [
    "![](img/demo.png)\n",
    "\n",
    "[Streamlit Demo](streamlit_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf6d2c-d47f-4b5c-8422-941f5cb49a20",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "**Original Slides authored by:** Siphu Langeni\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c56cf-dfa3-4ccc-bfa3-981d1c9656d7",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a10aeb-bff5-47f9-9fce-a30ff8a91edd",
   "metadata": {},
   "source": [
    "### Responsible AI\n",
    "\n",
    "> “Responsible AI **RAI** ensures that the development and deployment of AI systems aligns with ethical principles and values, including transparency and accountability. **RAI** principles and best practices help reduce the potential negative impacts of AI caused by machine bias.”\n",
    "\n",
    "![](https://h2o.ai/resources/data-sheet/responsible-ai-overview/_jcr_content/root/container/section_1441453307/par/advancedcolumncontro/columns1/image.coreimg.png/1674580925697/responsible-ai-ven-diagram-wide.png)\n",
    "\n",
    "[H2O.ai. (n.d.). Responsible AI overview. H2O.ai. Retrieved June 17, 2024](https://h2o.ai/resources/data-sheet/responsible-ai-overview/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff01b26-9e4f-4a61-b528-91d74a344586",
   "metadata": {},
   "source": [
    "### Pilars of Responsible AI \n",
    "\n",
    "##### 1. Bias and Fairness  \n",
    "- AI systems can inherit biases from training data or algorithms, leading to unfair outcomes (e.g., gender, racial, or cultural biases).  \n",
    "- **Actions**:  \n",
    "  - Evaluate datasets for bias and ensure diversity.  \n",
    "  - Use fairness-aware algorithms and tools to mitigate bias.  \n",
    "  - Regularly audit AI systems to identify and address biases.\n",
    "  - Remove features that are not necessary.\n",
    "\n",
    "##### 2. Privacy and Data Protection  \n",
    "- AI processes large amounts of personal and sensitive data, raising privacy concerns.  \n",
    "- **Actions**:  \n",
    "  - Follow data protection laws (depending on your region).  \n",
    "  - Anonymize and encrypt data to protect user privacy.\n",
    "  - Clearly communicate how user data will be collected, stored, and used.\n",
    "\n",
    "##### 3. Transparency and Explainability  \n",
    "- Many AI systems (e.g., deep learning models) operate as \"black boxes,\" making their decisions hard to interpret.  \n",
    "- **Actions**:  \n",
    "  - Use explainable AI (XAI) techniques to ensure decisions are understandable.  \n",
    "  - Provide documentation on how AI systems make decisions.  \n",
    "  - Be transparent with stakeholders about AI capabilities and limitations.\n",
    "\n",
    "##### 4. Accountability and Responsibility  \n",
    "- It is crucial to assign accountability for the outcomes of AI systems, especially when harm occurs.  \n",
    "- **Actions**:  \n",
    "  - Define roles and responsibilities for AI developers, deployers, and users. \n",
    "  - Establish processes to address issues caused by AI (e.g., incorrect decisions or harm). \n",
    "  - Regularly monitor AI performance to ensure compliance with ethical standards.\n",
    "\n",
    "##### 5. Safety and Security  \n",
    "- AI systems must be designed to ensure the safety of users and prevent misuse.  \n",
    "- **Actions**:  \n",
    "  - Protect AI models from adversarial attacks or hacking.  \n",
    "  - Ensure AI systems perform reliably and predictably, especially in critical applications like healthcare or autonomous vehicles.  \n",
    "  - Test AI systems rigorously for edge cases and failures.\n",
    "\n",
    "##### 6. Human Oversight  \n",
    "- AI systems should complement human decision-making rather than fully replacing it, especially in sensitive areas like law enforcement or healthcare.  \n",
    "- **Actions**:  \n",
    "  - Include mechanisms for human review of AI decisions.  \n",
    "  - Ensure humans remain in control of AI systems.  \n",
    "  - Promote AI as a decision-support tool rather than an autonomous agent.\n",
    "\n",
    "##### 7. Beneficence and Avoiding Harm  \n",
    "- AI should be used to create positive outcomes and avoid causing harm.  \n",
    "- **Actions**:  \n",
    "  - Evaluate potential risks and harms before deploying AI systems.  \n",
    "  - Consider the societal impact of AI on individuals and communities.  \n",
    "  - Avoid using AI for unethical purposes (e.g., surveillance without consent, weaponization).\n",
    "\n",
    "##### 8. Inclusivity and Accessibility  \n",
    "- AI should be designed to be accessible to diverse populations and not exclude certain groups.  \n",
    "- **Actions**:  \n",
    "  - Ensure AI systems are inclusive in their design and testing.  \n",
    "  - Address disparities in access to AI technologies.  \n",
    "  - Promote AI tools that improve accessibility for people with disabilities.\n",
    "\n",
    "##### 9. Environmental Impact  \n",
    "- AI development and training (e.g., large-scale models) consume significant energy resources.  \n",
    "- **Actions**:  \n",
    "  - Optimize AI models to reduce energy consumption.  \n",
    "  - Prioritize sustainability in AI infrastructure.  \n",
    "  - Consider the environmental costs of large-scale data processing.\n",
    "\n",
    "##### 10. Misuse and Malicious Applications  \n",
    "- AI can be misused for disinformation, deepfakes, fraud, or surveillance.  \n",
    "- **Actions**:  \n",
    "  - Develop safeguards against misuse.  \n",
    "  - Promote policies and guidelines that discourage malicious AI applications. \n",
    "  - Educate users and stakeholders about ethical AI usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f103e56-6728-4646-87d4-beb84bbbb6f4",
   "metadata": {},
   "source": [
    "#### Some unfortunate incidents:\n",
    "\n",
    "##### Amazon’s AI Recruitment Tool (2018)\n",
    "\n",
    "In 2018, Amazon developed an AI recruitment tool designed to automate and streamline the hiring process. However, the system was found to exhibit gender bias. The algorithm penalized resumes that contained words associated with women, such as “women’s chess club captain” or resumes from all-women’s colleges.\n",
    "\n",
    "This happened because the AI model was trained on historical hiring data, which reflected a male-dominated hiring trend over a decade. As a result, the AI learned to favor resumes that matched these biased patterns, perpetuating gender discrimination.\n",
    "\n",
    "##### Tom Cruise Deepfake Videos (2021)\n",
    "\n",
    "In 2021, videos of a deepfake Tom Cruise went viral on TikTok, created by a visual effects expert. The videos looked shockingly realistic, showing “Tom Cruise” performing magic tricks, golfing, and speaking casually.\n",
    "While the videos were entertaining, they highlighted how advanced deepfake technology can be misused to impersonate public figures, spread misinformation, or harm reputations.\n",
    "\n",
    "##### Cambridge Analytica and Facebook Ads (2016)\n",
    "\n",
    "During the 2016 U.S. presidential election, *Cambridge Analytica* used data from Facebook to create targeted propaganda ads. These ads aimed to influence voter behavior through tailored political messaging and emotional appeals.\n",
    "The misuse of personal data and AI algorithms amplified political polarization and misinformation, showcasing AI's role in modern propaganda.\n",
    "\n",
    "##### AI-Generated Content Misused by Students\n",
    "\n",
    "With the rise of tools like ChatGPT, some students have submitted AI-generated essays or assignments as their own work. These instances are flagged as plagiarism because the text lacks original thought and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511342aa-0789-488f-80cd-680d4f4cb53b",
   "metadata": {},
   "source": [
    "### Model Cards\n",
    "\n",
    "- [Model Cards for Model Reporting](https://arxiv.org/abs/1810.03993)\n",
    "  \n",
    "- Document key aspects of ML learning models\n",
    "\n",
    "> “We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d702ba-84fa-46d3-b238-614d095d50ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a301854c-5727-4a3e-82d7-6ea594f4cfeb",
   "metadata": {},
   "source": [
    "### Llama 2 by Meta\n",
    "\n",
    "- 7B - 13B - 70B parameter open source LLM released by Meta in July 2023\n",
    "- Free for research and commercial use\n",
    "- Base model pre-trained on publicly available online data sources\n",
    "- Chat model leverages publicly available instruction datasets and > 1M human annotations\n",
    "\n",
    "[Model Card](https://github.com/meta-llama/llama/blob/main/MODEL_CARD.md)\n",
    "\n",
    "[Responsible Use Guide](https://ai.meta.com/static-resource/responsible-use-guide/)\n",
    "\n",
    "[Research Paper](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f9f56-f3a4-49c2-aab2-b1d9e9265632",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "> \"To whom much is given, much is expected\"\n",
    "\n",
    "- Deploying LLMs at scale can be challenging yet very rewarding!\n",
    "- Ethical and responsible AI goes from data to deployment.\n",
    "- Make a habit of including good documentation of your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
